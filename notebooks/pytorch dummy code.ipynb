{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super parameters\n",
    "\n",
    "class params:\n",
    "    FeaLen = 50\n",
    "    Epoch = 10\n",
    "    BatchSize = 64\n",
    "    EmbedDim = 64\n",
    "    CateNum = 11\n",
    "    CateFeaLen = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self, featureNum, catfeaNum, catNum, embedDim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(featureNum, 2)\n",
    "        self.embed = nn.Embedding(num_embeddings=catNum, embedding_dim=embedDim)\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(catfeaNum*embedDim,500))\n",
    "        self.fc3 = nn.Linear(500, 1)\n",
    "    \n",
    "    def forward(self, x, catx):\n",
    "        # wide(linear) part\n",
    "        pred = self.fc1(x)\n",
    "        # deep part\n",
    "        out = self.embed(catx)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        # join part\n",
    "        pred = pred + out\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeData(Dataset):\n",
    "    def __init__(self, x, catx, y):\n",
    "        self.x = x\n",
    "        self.catx = catx\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = self.x[i]\n",
    "        catdata = self.catx[i]\n",
    "        label = self.y[i]\n",
    "        \n",
    "        return data, catdata, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(500,50)\n",
    "y = [1 if v>0.5 else 0 for v in np.random.rand(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "catx = np.random.rand(500, 10)\n",
    "\n",
    "catx = catx*10\n",
    "\n",
    "catx = catx.round()\n",
    "\n",
    "catx = catx.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype(np.float32)\n",
    "y = np.array(y, np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FakeData(x, catx, y)\n",
    "dataloader = DataLoader(dataset=dataset,\n",
    "                        batch_size=params.BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, dataloader):\n",
    "    # init model\n",
    "    model = WideAndDeep(params.FeaLen, \n",
    "                        params.CateFeaLen,\n",
    "                        params.CateNum, \n",
    "                        params.EmbedDim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch_i in range(params.Epoch):\n",
    "        epoch_loss = 0\n",
    "        for x,catx,y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model.forward(x, catx)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss /= 20\n",
    "        print(\"epoch {} loss {}\".format(epoch_i, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.2767000705003738\n",
      "epoch 1 loss 0.2763074904680252\n",
      "epoch 2 loss 0.2759425610303879\n",
      "epoch 3 loss 0.2756965756416321\n",
      "epoch 4 loss 0.27551392614841463\n",
      "epoch 5 loss 0.275350022315979\n",
      "epoch 6 loss 0.2751928001642227\n",
      "epoch 7 loss 0.27504209578037264\n",
      "epoch 8 loss 0.2748973101377487\n",
      "epoch 9 loss 0.2747560262680054\n"
     ]
    }
   ],
   "source": [
    "train_model(params, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
