{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: movie lens 100k\n",
    "# Include 943 user and 1682 movies.\n",
    "\n",
    "userids = []\n",
    "movieids = []\n",
    "with open('./ml-100k/u.data', 'r') as f:\n",
    "    for line in f:\n",
    "        userid, itemid, rating, timestamp = line.rstrip().split('\\t')\n",
    "        userid, itemid = int(userid), int(itemid)\n",
    "        userids.append(userid)\n",
    "        movieids.append(itemid)\n",
    "\n",
    "\n",
    "ratings = tf.data.Dataset.from_tensor_slices({'user_id': userids, 'movie_id': movieids})\n",
    "\n",
    "movies = tf.data.Dataset.from_tensor_slices(list(set(movieids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_USER = 1000\n",
    "N_ITEM = 2000\n",
    "N_EMBED = 32 # 64\n",
    "N_BATCH = 128\n",
    "\n",
    "# Build a model.\n",
    "class Model(tfrs.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user representation.\n",
    "    self.user_model = tf.keras.layers.Embedding(\n",
    "        input_dim=N_USER, output_dim=N_EMBED)\n",
    "    # Set up movie representation.\n",
    "    self.item_model = tf.keras.layers.Embedding(\n",
    "        input_dim=N_ITEM, output_dim=N_EMBED)\n",
    "    # Set up a retrieval task and evaluation metrics over the\n",
    "    # entire dataset of candidates.\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(N_BATCH).map(self.item_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    movie_embeddings = self.item_model(features[\"movie_id\"])\n",
    "\n",
    "    return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "model = Model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      "10/10 [==============================] - 17s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0114 - factorized_top_k/top_10_categorical_accuracy: 0.0234 - factorized_top_k/top_50_categorical_accuracy: 0.1054 - factorized_top_k/top_100_categorical_accuracy: 0.1840 - loss: 69813.3260 - regularization_loss: 0.0000e+00 - total_loss: 69813.3260\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 19s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0194 - factorized_top_k/top_10_categorical_accuracy: 0.0395 - factorized_top_k/top_50_categorical_accuracy: 0.1694 - factorized_top_k/top_100_categorical_accuracy: 0.2957 - loss: 67495.4411 - regularization_loss: 0.0000e+00 - total_loss: 67495.4411\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 21s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0042 - factorized_top_k/top_5_categorical_accuracy: 0.0234 - factorized_top_k/top_10_categorical_accuracy: 0.0468 - factorized_top_k/top_50_categorical_accuracy: 0.1887 - factorized_top_k/top_100_categorical_accuracy: 0.3173 - loss: 66332.5334 - regularization_loss: 0.0000e+00 - total_loss: 66332.5334\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 19s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0051 - factorized_top_k/top_5_categorical_accuracy: 0.0269 - factorized_top_k/top_10_categorical_accuracy: 0.0519 - factorized_top_k/top_50_categorical_accuracy: 0.2042 - factorized_top_k/top_100_categorical_accuracy: 0.3355 - loss: 65643.2855 - regularization_loss: 0.0000e+00 - total_loss: 65643.2855\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 19s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0051 - factorized_top_k/top_5_categorical_accuracy: 0.0294 - factorized_top_k/top_10_categorical_accuracy: 0.0563 - factorized_top_k/top_50_categorical_accuracy: 0.2160 - factorized_top_k/top_100_categorical_accuracy: 0.3496 - loss: 65140.6349 - regularization_loss: 0.0000e+00 - total_loss: 65140.6349\n",
      "5/5 [==============================] - 2s 493ms/step - factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0069 - factorized_top_k/top_10_categorical_accuracy: 0.0154 - factorized_top_k/top_50_categorical_accuracy: 0.1094 - factorized_top_k/top_100_categorical_accuracy: 0.2174 - loss: 31147.7835 - regularization_loss: 0.0000e+00 - total_loss: 31147.7835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0009500000160187483,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.006850000005215406,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.015449999831616879,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.10939999669790268,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.21739999949932098,\n",
       " 'loss': 28293.48828125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28293.48828125}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "# Train.\n",
    "model.fit(train.batch(8192), epochs=5)\n",
    "\n",
    "# Evaluate.\n",
    "model.evaluate(test.batch(4096), return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 48: [ 136  524  604 1064  480  243  615  482  427  486]\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index(movies.batch(100).map(model.item_model), movies)\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([48]))\n",
    "print(f\"Recommendations for user 48: {titles[0, :10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "[1] https://tensorflow.google.cn/recommenders/examples/basic_retrieval#building_a_candidate_ann_index\n",
    "\n",
    "[2] https://github.com/tensorflow/recommenders/releases/tag/v0.2.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf02",
   "language": "python",
   "name": "tf02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
